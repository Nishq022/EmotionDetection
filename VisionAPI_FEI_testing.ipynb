{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy_test\\image0000626.jpg\n",
      "happy_test\\image0000629.jpg\n",
      "happy_test\\image0000635.jpg\n",
      "happy_test\\image0000636.jpg\n",
      "happy_test\\image0000637.jpg\n",
      "happy_test\\image0000638.jpg\n",
      "happy_test\\image0000642.jpg\n",
      "happy_test\\image0000644.jpg\n",
      "happy_test\\image0000647.jpg\n",
      "happy_test\\image0000649.jpg\n",
      "sad_test\\image0006100.jpg\n",
      "sad_test\\image0006101.jpg\n",
      "sad_test\\image0006103.jpg\n",
      "sad_test\\image0006107.jpg\n",
      "sad_test\\image0006117.jpg\n",
      "angry_test\\image0012043.jpg\n",
      "angry_test\\image0012048.jpg\n",
      "angry_test\\image0012060.jpg\n",
      "angry_test\\image0012073.jpg\n",
      "angry_test\\image0012085.jpg\n",
      "surprise_test\\image0019618.jpg\n",
      "surprise_test\\image0019628.jpg\n",
      "surprise_test\\image0019636.jpg\n",
      "surprise_test\\image0019641.jpg\n",
      "surprise_test\\image0019642.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "    \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"amitabh_apikey.json\"\n",
    "from google.cloud import vision\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "output_dict['Filepath'] = []\n",
    "output_dict['Label'] = []\n",
    "output_dict['Happy Confidence'] = []\n",
    "output_dict['Angry Confidence'] = []\n",
    "output_dict['Sad Confidence'] = []\n",
    "output_dict['Surprise Confidence'] = []\n",
    "output_dict['Overall Confidence'] = []\n",
    "\n",
    "html = \"\"\"<!DOCTYPE html> \n",
    "<html>\n",
    "\n",
    "<head>\n",
    "    <link rel=\"stylesheet\" href=\"style.css\">\n",
    "    <title>VisionAPI Testing</title>\n",
    "</head>\n",
    "<body>\n",
    "    <center>\n",
    "        <h1>VisionAPI testing</h1>\n",
    "    </center>\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all happy-labelled images\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Happy</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            <th align=\"center\" width=200 >Overall Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/FEI_frontal/*b.jpg'):\n",
    "    print(filepath)\n",
    "    with io.open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    \n",
    "    image = vision.types.Image(content=content)\n",
    "    face_response = client.face_detection(image=image, max_results=5).face_annotations\n",
    "    \n",
    "    if face_response: \n",
    "        emotion_dict = {}\n",
    "        emotion_dict['Happy'] = face_response[0].joy_likelihood\n",
    "        emotion_dict['Sad'] = face_response[0].sorrow_likelihood\n",
    "        emotion_dict['Angry'] = face_response[0].anger_likelihood\n",
    "        emotion_dict['Surprise'] = face_response[0].surprise_likelihood\n",
    "\n",
    "        output_dict['Filepath'].append(filepath)\n",
    "        output_dict['Label'].append('Happy')\n",
    "        output_dict['Happy Confidence'].append(face_response[0].joy_likelihood)\n",
    "        output_dict['Sad Confidence'].append(face_response[0].sorrow_likelihood)\n",
    "        output_dict['Angry Confidence'].append(face_response[0].anger_likelihood)\n",
    "        output_dict['Surprise Confidence'].append(face_response[0].surprise_likelihood)\n",
    "        output_dict['Overall Confidence'].append(face_response[0].detection_confidence)\n",
    "\n",
    "        emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "        emotion_confidence = str(int(max(emotion_dict.items(), key=operator.itemgetter(1))[1])/5*100)\n",
    "        overall_confidence = str(round(face_response[0].detection_confidence *100))\n",
    "\n",
    "        html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion_confidence+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+overall_confidence+\"\"\"</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "\n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all neutral-labelled images\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Neutral</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            <th align=\"center\" width=200 >Overall Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/FEI_frontal/*a.jpg'):\n",
    "    print(filepath)\n",
    "    with io.open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "        \n",
    "    image = vision.types.Image(content=content)\n",
    "    face_response = client.face_detection(image=image, max_results=5).face_annotations\n",
    "    \n",
    "    if face_response:\n",
    "        \n",
    "        emotion_dict = {}\n",
    "        emotion_dict['Happy'] = face_response[0].joy_likelihood\n",
    "        emotion_dict['Sad'] = face_response[0].sorrow_likelihood\n",
    "        emotion_dict['Angry'] = face_response[0].anger_likelihood\n",
    "        emotion_dict['Surprise'] = face_response[0].surprise_likelihood\n",
    "\n",
    "        output_dict['Filepath'].append(filepath)\n",
    "        output_dict['Label'].append('Neutral')\n",
    "        output_dict['Happy Confidence'].append(face_response[0].joy_likelihood)\n",
    "        output_dict['Sad Confidence'].append(face_response[0].sorrow_likelihood)\n",
    "        output_dict['Angry Confidence'].append(face_response[0].anger_likelihood)\n",
    "        output_dict['Surprise Confidence'].append(face_response[0].surprise_likelihood)\n",
    "        output_dict['Overall Confidence'].append(face_response[0].detection_confidence)\n",
    "\n",
    "        emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "        emotion_confidence = str(int(max(emotion_dict.items(), key=operator.itemgetter(1))[1])/5*100)\n",
    "        overall_confidence = str(round(face_response[0].detection_confidence *100))\n",
    "\n",
    "        html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion_confidence+\"\"\"%</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+overall_confidence+\"\"\"%</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "\n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "html+=\"\"\"</body>\"\"\"\n",
    "Html_file= open(\"visionAPI_FEI_observation_test_output.html\",\"w\",encoding=\"utf-8\")\n",
    "Html_file.write(html)\n",
    "Html_file.close()\n",
    "\n",
    "df = pd.DataFrame(output_dict)\n",
    "df.to_csv('visionAPI_FEI_raw_test_data_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

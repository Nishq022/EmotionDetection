{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\nishq\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\nishq\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\nishq\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\nishq\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\nishq\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\nishq\\Desktop\\Tensorflow-Bootcamp-master_backup\\Infinite Analytics\\Emotion Detection\\AffectNet_pretrained_model\\model_resnext-96000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorboard\n",
    "import tflearn\n",
    "\n",
    "n = 5\n",
    "\n",
    "# Real-time data preprocessing\n",
    "img_prep = tflearn.ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center(per_channel=True, mean=[0.53990436 , 0.4405486  , 0.39328504])\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_crop([49, 49], padding=4)\n",
    "\n",
    "# Building Residual Network\n",
    "net = tflearn.input_data(shape=[None, 49, 49, 3],\n",
    "                         data_preprocessing=img_prep,\n",
    "                         data_augmentation=img_aug)\n",
    "net = tflearn.conv_2d(net, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "net = tflearn.resnext_block(net, n, 16, 32)\n",
    "net = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 32, 32)\n",
    "net = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 64, 32)\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)\n",
    "# Regression\n",
    "net = tflearn.fully_connected(net, 11, activation='softmax')\n",
    "opt = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "net = tflearn.regression(net, optimizer=opt,\n",
    "                         loss='categorical_crossentropy')\n",
    "# Training\n",
    "model = tflearn.DNN(net, checkpoint_path='Snapshots/model_resnext',\n",
    "                    max_checkpoints=10, tensorboard_verbose=0, tensorboard_dir='Logs/',\n",
    "                    clip_gradients=0.)\n",
    "\n",
    "model.load('AffectNet_pretrained_model/model_resnext-96000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/AffectNet_subset/happy\\image0000626.jpg\n",
      "Happy\n",
      "95.28958201408386\n",
      "Datasets/AffectNet_subset/happy\\image0000629.jpg\n",
      "No-Face\n",
      "81.08367323875427\n",
      "Datasets/AffectNet_subset/happy\\image0000635.jpg\n",
      "No-Face\n",
      "50.49096941947937\n",
      "Datasets/AffectNet_subset/happy\\image0000636.jpg\n",
      "Happy\n",
      "49.02474284172058\n",
      "Datasets/AffectNet_subset/happy\\image0000637.jpg\n",
      "Happy\n",
      "68.50424408912659\n",
      "Datasets/AffectNet_subset/happy\\image0000638.jpg\n",
      "Neutral\n",
      "26.862531900405884\n",
      "Datasets/AffectNet_subset/happy\\image0000642.jpg\n",
      "Happy\n",
      "82.99608826637268\n",
      "Datasets/AffectNet_subset/happy\\image0000644.jpg\n",
      "Happy\n",
      "81.32333755493164\n",
      "Datasets/AffectNet_subset/happy\\image0000647.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8d8f6f734f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0memotion_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m    256\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_dict_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tflearn\\helpers\\evaluator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, feed_dict)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# Prediction for each tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tflearn\\config.py\u001b[0m in \u001b[0;36mis_training\u001b[1;34m(is_training, session)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'is_training_ops'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'is_training_ops'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \"\"\"\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5179\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5180\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5181\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import operator\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "output_dict['Filepath'] = []\n",
    "output_dict['Label'] = []\n",
    "output_dict['Neutral Confidence'] = []\n",
    "output_dict['Happy Confidence'] = []\n",
    "output_dict['Sad Confidence'] = []\n",
    "output_dict['Surprise Confidence'] = []\n",
    "output_dict['Fear Confidence'] = []\n",
    "output_dict['Disgust Confidence'] = []\n",
    "output_dict['Anger Confidence'] = []\n",
    "output_dict['Contempt Confidence'] = []\n",
    "output_dict['None Confidence'] = []\n",
    "output_dict['Uncertain Confidence'] = []\n",
    "output_dict['No-Face Confidence']  = []\n",
    "sess= tf.Session()\n",
    "\n",
    "html = \"\"\"<!DOCTYPE html> \n",
    "<html>\n",
    "\n",
    "<head>\n",
    "    <link rel=\"stylesheet\" href=\"style.css\">\n",
    "    <title>AffectNet Pretrained Model Testing</title>\n",
    "</head>\n",
    "<body>\n",
    "    <center>\n",
    "        <h1>AffectNet Pretrained Model testing</h1>\n",
    "    </center>\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all happy-labelled images\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Happy</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/AffectNet_subset/happy/*.jpg'):\n",
    "    print(filepath)\n",
    "    \n",
    "    img = tf.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize_images(img, (49, 49))\n",
    "    img = img.eval(session=sess) # convert to numpy array\n",
    "    img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "    img = img/255.0\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    emotion_dict = {}\n",
    "    emotion_dict['Neutral'] = prediction[0][0]\n",
    "    emotion_dict['Happy'] = prediction[0][1]\n",
    "    emotion_dict['Sad'] = prediction[0][2]\n",
    "    emotion_dict['Surprise'] = prediction[0][3]\n",
    "    emotion_dict['Fear'] = prediction[0][4]\n",
    "    emotion_dict['Disgust'] = prediction[0][5]\n",
    "    emotion_dict['Anger'] = prediction[0][6]\n",
    "    emotion_dict['Contempt'] = prediction[0][7]\n",
    "    emotion_dict['None'] = prediction[0][8]\n",
    "    emotion_dict['Uncertain'] = prediction[0][9]\n",
    "    emotion_dict['No-Face'] = prediction[0][10]\n",
    "    \n",
    "    output_dict['Filepath'].append(filepath)\n",
    "    output_dict['Label'].append('Happy')\n",
    "    output_dict['Neutral Confidence'].append(prediction[0][0])\n",
    "    output_dict['Happy Confidence'].append(prediction[0][1])\n",
    "    output_dict['Sad Confidence'].append(prediction[0][2])\n",
    "    output_dict['Surprise Confidence'].append(prediction[0][3])\n",
    "    output_dict['Fear Confidence'].append(prediction[0][4])\n",
    "    output_dict['Disgust Confidence'].append(prediction[0][5])\n",
    "    output_dict['Anger Confidence'].append(prediction[0][6])\n",
    "    output_dict['Contempt Confidence'].append(prediction[0][7])\n",
    "    output_dict['None Confidence'].append(prediction[0][8])\n",
    "    output_dict['Uncertain Confidence'].append(prediction[0][9])\n",
    "    output_dict['No-Face Confidence'].append(prediction[0][10]) \n",
    "    \n",
    "    emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "    emotion_confidence = max(emotion_dict.items(), key=operator.itemgetter(1))[1] *100\n",
    "    \n",
    "    html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+str(round(emotion_confidence))+\"\"\"%</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "    print(emotion)\n",
    "    print(emotion_confidence)\n",
    "    \n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all sad-labelled images\n",
    "\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Sad</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/AffectNet_subset/sad/*.jpg'):\n",
    "    print(filepath)\n",
    "    \n",
    "    img = tf.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize_images(img, (49, 49))\n",
    "    img = img.eval(session=sess) # convert to numpy array\n",
    "    img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "    img = img/255.0\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    emotion_dict = {}\n",
    "    emotion_dict['Neutral'] = prediction[0][0]\n",
    "    emotion_dict['Happy'] = prediction[0][1]\n",
    "    emotion_dict['Sad'] = prediction[0][2]\n",
    "    emotion_dict['Surprise'] = prediction[0][3]\n",
    "    emotion_dict['Fear'] = prediction[0][4]\n",
    "    emotion_dict['Disgust'] = prediction[0][5]\n",
    "    emotion_dict['Anger'] = prediction[0][6]\n",
    "    emotion_dict['Contempt'] = prediction[0][7]\n",
    "    emotion_dict['None'] = prediction[0][8]\n",
    "    emotion_dict['Uncertain'] = prediction[0][9]\n",
    "    emotion_dict['No-Face'] = prediction[0][10]\n",
    "    \n",
    "    output_dict['Filepath'].append(filepath)\n",
    "    output_dict['Label'].append('Sad')\n",
    "    output_dict['Neutral Confidence'].append(prediction[0][0])\n",
    "    output_dict['Happy Confidence'].append(prediction[0][1])\n",
    "    output_dict['Sad Confidence'].append(prediction[0][2])\n",
    "    output_dict['Surprise Confidence'].append(prediction[0][3])\n",
    "    output_dict['Fear Confidence'].append(prediction[0][4])\n",
    "    output_dict['Disgust Confidence'].append(prediction[0][5])\n",
    "    output_dict['Anger Confidence'].append(prediction[0][6])\n",
    "    output_dict['Contempt Confidence'].append(prediction[0][7])\n",
    "    output_dict['None Confidence'].append(prediction[0][8])\n",
    "    output_dict['Uncertain Confidence'].append(prediction[0][9])\n",
    "    output_dict['No-Face Confidence'].append(prediction[0][10]) \n",
    "    \n",
    "    emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "    emotion_confidence = max(emotion_dict.items(), key=operator.itemgetter(1))[1] *100\n",
    "    \n",
    "    html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+str(round(emotion_confidence))+\"\"\"%</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "    print(emotion)\n",
    "    print(emotion_confidence)\n",
    "    \n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all angry-labelled images\n",
    "\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Angry</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/AffectNet_subset/angry/*.jpg'):\n",
    "    print(filepath)\n",
    "    \n",
    "    img = tf.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize_images(img, (49, 49))\n",
    "    img = img.eval(session=sess) # convert to numpy array\n",
    "    img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "    img = img/255.0\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    emotion_dict = {}\n",
    "    emotion_dict['Neutral'] = prediction[0][0]\n",
    "    emotion_dict['Happy'] = prediction[0][1]\n",
    "    emotion_dict['Sad'] = prediction[0][2]\n",
    "    emotion_dict['Surprise'] = prediction[0][3]\n",
    "    emotion_dict['Fear'] = prediction[0][4]\n",
    "    emotion_dict['Disgust'] = prediction[0][5]\n",
    "    emotion_dict['Anger'] = prediction[0][6]\n",
    "    emotion_dict['Contempt'] = prediction[0][7]\n",
    "    emotion_dict['None'] = prediction[0][8]\n",
    "    emotion_dict['Uncertain'] = prediction[0][9]\n",
    "    emotion_dict['No-Face'] = prediction[0][10]\n",
    "    \n",
    "    output_dict['Filepath'].append(filepath)\n",
    "    output_dict['Label'].append('Angry')\n",
    "    output_dict['Neutral Confidence'].append(prediction[0][0])\n",
    "    output_dict['Happy Confidence'].append(prediction[0][1])\n",
    "    output_dict['Sad Confidence'].append(prediction[0][2])\n",
    "    output_dict['Surprise Confidence'].append(prediction[0][3])\n",
    "    output_dict['Fear Confidence'].append(prediction[0][4])\n",
    "    output_dict['Disgust Confidence'].append(prediction[0][5])\n",
    "    output_dict['Anger Confidence'].append(prediction[0][6])\n",
    "    output_dict['Contempt Confidence'].append(prediction[0][7])\n",
    "    output_dict['None Confidence'].append(prediction[0][8])\n",
    "    output_dict['Uncertain Confidence'].append(prediction[0][9])\n",
    "    output_dict['No-Face Confidence'].append(prediction[0][10]) \n",
    "    \n",
    "    emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "    emotion_confidence = max(emotion_dict.items(), key=operator.itemgetter(1))[1] *100\n",
    "    \n",
    "    html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+str(round(emotion_confidence))+\"\"\"%</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "    print(emotion)\n",
    "    print(emotion_confidence)\n",
    "    \n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------------------------- Get all sad-labelled images\n",
    "\n",
    "html+= \"\"\"<center>\n",
    "        <h1>Surprise</h1>\n",
    "    </center>\n",
    "    \n",
    "    <table align=\"center\" >\n",
    "\n",
    "        <tr>\n",
    "            \n",
    "            <th align=\"center\" width=200 >Photo</th>\n",
    "            <th align=\"center\" width=200 >Emotion</th>\n",
    "            <th align=\"center\" width=200 >Emotion Confidence</th>\n",
    "            \n",
    "        </tr>\"\"\"\n",
    "\n",
    "\n",
    "for filepath in glob.iglob('Datasets/AffectNet_subset/surprise/*.jpg'):\n",
    "    print(filepath)\n",
    "    \n",
    "    img = tf.read_file(filepath)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize_images(img, (49, 49))\n",
    "    img = img.eval(session=sess) # convert to numpy array\n",
    "    img = np.expand_dims(img, 0) # make 'batch' of 1\n",
    "    img = img/255.0\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    emotion_dict = {}\n",
    "    emotion_dict['Neutral'] = prediction[0][0]\n",
    "    emotion_dict['Happy'] = prediction[0][1]\n",
    "    emotion_dict['Sad'] = prediction[0][2]\n",
    "    emotion_dict['Surprise'] = prediction[0][3]\n",
    "    emotion_dict['Fear'] = prediction[0][4]\n",
    "    emotion_dict['Disgust'] = prediction[0][5]\n",
    "    emotion_dict['Anger'] = prediction[0][6]\n",
    "    emotion_dict['Contempt'] = prediction[0][7]\n",
    "    emotion_dict['None'] = prediction[0][8]\n",
    "    emotion_dict['Uncertain'] = prediction[0][9]\n",
    "    emotion_dict['No-Face'] = prediction[0][10]\n",
    "    \n",
    "    output_dict['Filepath'].append(filepath)\n",
    "    output_dict['Label'].append('Surprise')\n",
    "    output_dict['Neutral Confidence'].append(prediction[0][0])\n",
    "    output_dict['Happy Confidence'].append(prediction[0][1])\n",
    "    output_dict['Sad Confidence'].append(prediction[0][2])\n",
    "    output_dict['Surprise Confidence'].append(prediction[0][3])\n",
    "    output_dict['Fear Confidence'].append(prediction[0][4])\n",
    "    output_dict['Disgust Confidence'].append(prediction[0][5])\n",
    "    output_dict['Anger Confidence'].append(prediction[0][6])\n",
    "    output_dict['Contempt Confidence'].append(prediction[0][7])\n",
    "    output_dict['None Confidence'].append(prediction[0][8])\n",
    "    output_dict['Uncertain Confidence'].append(prediction[0][9])\n",
    "    output_dict['No-Face Confidence'].append(prediction[0][10]) \n",
    "    \n",
    "    emotion = str(max(emotion_dict.items(), key=operator.itemgetter(1))[0])\n",
    "    emotion_confidence = max(emotion_dict.items(), key=operator.itemgetter(1))[1] *100\n",
    "    \n",
    "    html+= \"\"\"<tr align=\"center\">\n",
    "\n",
    "                <td><img src=\"\"\"+'\"'+str(filepath)+'\"'+\"\"\" alt=\"\" border=3 height=200 width=200></img></td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+emotion+\"\"\"</td>\n",
    "                <td align=\"center\" height=200 width=200 >\"\"\"+str(round(emotion_confidence))+\"\"\"%</td>\n",
    "\n",
    "            </tr>\"\"\"\n",
    "    print(emotion)\n",
    "    print(emotion_confidence)\n",
    "    \n",
    "html+=\"\"\"</table>\"\"\"\n",
    "\n",
    "html+=\"\"\"</body>\"\"\"\n",
    "Html_file= open(\"AffectNet_observation_test_output.html\",\"w\",encoding=\"utf-8\")\n",
    "Html_file.write(html)\n",
    "Html_file.close()\n",
    "\n",
    "df = pd.DataFrame(output_dict)\n",
    "df.to_csv('AffectNet_raw_test_data_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
